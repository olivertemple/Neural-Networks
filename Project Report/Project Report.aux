\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{AI-hypotheses}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}What is a neural network?}{3}{subsection.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Neural Network}}{3}{figure.1}\protected@file@percent }
\newlabel{fig:neural_network}{{1}{3}{Neural Network}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Project Goal}{3}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Uses of neural networks}{3}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Different types of neural networks}{4}{subsection.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.1}Perceptron}{4}{subsubsection.1.4.1}\protected@file@percent }
\newlabel{eq:perceptron}{{1}{5}{Perceptron}{equation.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Perceptron}}{5}{figure.2}\protected@file@percent }
\newlabel{fig:perceptron}{{2}{5}{Perceptron}{figure.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.2}Feed Forward Neural Network}{5}{subsubsection.1.4.2}\protected@file@percent }
\newlabel{eq:feed-forward}{{2}{5}{Feed Forward Neural Network}{equation.1.2}{}}
\citation{convolutionalnn}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.3}Multi-Layer Perceptron}{6}{subsubsection.1.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.4}Convolutional Neural Network}{6}{subsubsection.1.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Convolutional Neural Network}}{6}{figure.3}\protected@file@percent }
\newlabel{fig:convolutional_neural_network}{{3}{6}{Convolutional Neural Network}{figure.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.5}Recurrent Neural Network}{6}{subsubsection.1.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.6}Long Short-Term Memory}{7}{subsubsection.1.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Motivation}{7}{subsection.1.5}\protected@file@percent }
\citation{History of Neural Networks}
\@writefile{toc}{\contentsline {section}{\numberline {2}The History of Neural Networks}{8}{section.2}\protected@file@percent }
\newlabel{eq:Widrow-Hoff}{{3}{8}{The History of Neural Networks}{equation.2.3}{}}
\citation{Bias in Artificial Intelligence}
\@writefile{toc}{\contentsline {section}{\numberline {3}Bias in Artificial Intelligence}{10}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}What causes bias in AI?}{10}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Data Bias}{10}{subsubsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Societal Bias}{10}{subsubsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Examples of Bias in AI}{10}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}PortraitAI Art Generator}{10}{subsubsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Twitter Photo Cropping}{11}{subsubsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}How Neural Networks Work}{12}{section.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Multilayer Perceptron}}{12}{figure.4}\protected@file@percent }
\newlabel{fig:multilayer-perceptron}{{4}{12}{Multilayer Perceptron}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Structure}{12}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Forward Propagation}{13}{subsection.4.2}\protected@file@percent }
\newlabel{eq:forward-propagation}{{4}{13}{Forward Propagation}{equation.4.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Activation Functions}{13}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Sigmoid}{13}{subsubsection.4.3.1}\protected@file@percent }
\newlabel{eq:sigmoid}{{5}{13}{Sigmoid}{equation.4.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Tanh}{13}{subsubsection.4.3.2}\protected@file@percent }
\newlabel{eq:tanh}{{6}{13}{Tanh}{equation.4.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Sigmoid Function}}{14}{figure.5}\protected@file@percent }
\newlabel{fig:sigmoid_function}{{5}{14}{Sigmoid Function}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Tanh Function}}{14}{figure.6}\protected@file@percent }
\newlabel{fig:tanh}{{6}{14}{Tanh Function}{figure.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}ReLU}{14}{subsubsection.4.3.3}\protected@file@percent }
\newlabel{eq:relu}{{7}{14}{ReLU}{equation.4.7}{}}
\citation{Loss Functions}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces ReLU Function}}{15}{figure.7}\protected@file@percent }
\newlabel{fig:relu}{{7}{15}{ReLU Function}{figure.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.4}Leaky ReLU}{15}{subsubsection.4.3.4}\protected@file@percent }
\newlabel{eq:leaky-relu}{{8}{15}{Leaky ReLU}{equation.4.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Loss Function}{15}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}Mean Squared Error}{15}{subsubsection.4.4.1}\protected@file@percent }
\newlabel{eq:MSE}{{9}{15}{Mean Squared Error}{equation.4.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Leaky ReLU Function}}{16}{figure.8}\protected@file@percent }
\newlabel{fig:leaky-relu}{{8}{16}{Leaky ReLU Function}{figure.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.2}Cross Entropy Loss}{16}{subsubsection.4.4.2}\protected@file@percent }
\newlabel{eq:CEL}{{10}{16}{Cross Entropy Loss}{equation.4.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Backpropagation}{16}{subsection.4.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Loss against Weight}}{17}{figure.9}\protected@file@percent }
\newlabel{fig:loss-vs-weights}{{9}{17}{Loss against Weight}{figure.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Training}{17}{subsection.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Coding a Neural Network}{18}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Data}{18}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Splitting the Data}{18}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Defining the Model}{18}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Layers}{18}{subsubsection.5.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}Loss Function}{18}{subsubsection.5.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3}Activation Function}{19}{subsubsection.5.3.3}\protected@file@percent }
\newlabel{eq:sigmoid-derivative}{{11}{19}{Activation Function}{equation.5.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Training the Model}{19}{subsection.5.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Loss of neural network over epochs}}{19}{figure.10}\protected@file@percent }
\newlabel{fig:loss}{{10}{19}{Loss of neural network over epochs}{figure.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.1}Over Fitting}{19}{subsubsection.5.4.1}\protected@file@percent }
\citation{curse-of-dimensionality}
\citation{tensorflow}
\citation{pytorch}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.2}The Curse of Dimensionality}{20}{subsubsection.5.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.3}Local Minima}{20}{subsubsection.5.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Testing the Model}{20}{subsection.5.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Sample inputs of neural network}}{20}{figure.11}\protected@file@percent }
\newlabel{fig:sample-predictions}{{11}{20}{Sample inputs of neural network}{figure.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Discussion of Results}{21}{subsection.5.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{22}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Appendix}{23}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Vector Dot Product}{23}{subsection.7.1}\protected@file@percent }
\newlabel{eq:vector-dot-product}{{12}{23}{Vector Dot Product}{equation.7.12}{}}
\newlabel{eq:vector-dot-product-2}{{13}{23}{Vector Dot Product}{equation.7.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}MNIST Dataset}{23}{subsection.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Python 3.9.10 Code}{25}{subsection.7.3}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{../network/main.py}{25}{lstlisting.-1}\protected@file@percent }
\bibcite{History of Neural Networks}{1}
\bibcite{Bias in Artificial Intelligence}{2}
\bibcite{Loss Functions}{3}
\bibcite{AI-hypotheses}{4}
\bibcite{curse-of-dimensionality}{5}
\bibcite{3Blue1Brown Neural Networks}{6}
\bibcite{convolutionalnn}{7}
\bibcite{vonneumann}{8}
\bibcite{tensorflow}{9}
\bibcite{pytorch}{10}
\gdef \@abspage@last{30}
